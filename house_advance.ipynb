{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4388640c",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b0df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#load data\n",
    "X_full = pd.read_csv('/Users/chuwen/Desktop/kaggle/House_pricing/data/train.csv', index_col = 'Id')\n",
    "X_test_full = pd.read_csv('/Users/chuwen/Desktop/kaggle/House_pricing/data/test.csv', index_col = 'Id')\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)#drop the rows with null target values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0378be7",
   "metadata": {},
   "source": [
    "## take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03290e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a6c46",
   "metadata": {},
   "source": [
    "## take a look at the target value \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prices = pd.DataFrame({\"price\":X_full[\"SalePrice\"], \"log(price + 1)\":np.log1p(X_full[\"SalePrice\"])})\n",
    "prices.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d7b04",
   "metadata": {},
   "source": [
    "After normalization, the distribution is a bell curve. Use log plus one to normalize the target data and remember to change it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b2e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(X_full.pop('SalePrice'))\n",
    "# take the normalized target out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08adac",
   "metadata": {},
   "source": [
    "## handle the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eab01e",
   "metadata": {},
   "source": [
    "### in some cases, like 'MSSubClass' is categorical data but regonized as numerical data. we need to change it's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ef1af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "befor: int64\n",
      "after: object\n"
     ]
    }
   ],
   "source": [
    "print('befor:', X_full['MSSubClass'].dtypes)\n",
    "X_full['MSSubClass'] = X_full['MSSubClass'].astype(str)\n",
    "X_test_full['MSSubClass'] = X_test_full['MSSubClass'].astype(str)\n",
    "print('after:', X_full['MSSubClass'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a93fb7",
   "metadata": {},
   "source": [
    "### seperate numerical and categorical data with low cardinality, make train, valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96242a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 15 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d38e7c",
   "metadata": {},
   "source": [
    "## Implement pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cef0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant') # Your code here\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f1d07",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4792ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea045a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# modle1: ridge with bagging\n",
    "ridge = Ridge(15)\n",
    "\n",
    "params = [1, 10, 15, 20, 25, 30, 40]\n",
    "test_scores = []\n",
    "for param in params:\n",
    "    my_pipeline = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', BaggingRegressor(n_estimators=param, base_estimator=ridge))])\n",
    "    test_score = -cross_val_score(my_pipeline, X_train, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
    "    test_scores.append(np.mean(test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(params, test_scores)\n",
    "plt.title(\"n_estimator vs CV Error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32973497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2:xgboost\n",
    "from xgboost import XGBRegressor\n",
    "params = [200, 400, 600, 800, 1000, 1200]\n",
    "test_scores = []\n",
    "for param in params:\n",
    "    my_pipeline = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', XGBRegressor(n_estimators=param, learning_rate = 0.05, n_jobs=4))])\n",
    "    test_score = -cross_val_score(my_pipeline, X_train, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
    "    test_scores.append(np.mean(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(params, test_scores)\n",
    "plt.title(\"n_estimator vs CV Error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3:gradient boost\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "params = [200, 400, 600, 800, 1000, 1200]\n",
    "test_scores = []\n",
    "for param in params:\n",
    "    my_pipeline = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', GradientBoostingRegressor(n_estimators=param))])\n",
    "    test_score = -cross_val_score(my_pipeline, X_train, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
    "    test_scores.append(np.mean(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e929ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(params, test_scores)\n",
    "plt.title(\"n_estimator vs CV Error\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [50, 100, 150, 200]\n",
    "test_scores = []\n",
    "for param in params:\n",
    "    my_pipeline = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', GradientBoostingRegressor(n_estimators=param))])\n",
    "    test_score = -cross_val_score(my_pipeline, X_train, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
    "    test_scores.append(np.mean(test_score))\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cbb38",
   "metadata": {},
   "source": [
    "## make predictions with tunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dcbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_or_MAE(predic, val):\n",
    "    predict_or = np.expm1(predic)\n",
    "    val_or = np.expm1(val)\n",
    "    score = mean_absolute_error(predict_or, val_or)\n",
    "    print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c38b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 22111.659457968846\n"
     ]
    }
   ],
   "source": [
    "my_pipeline1 = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', BaggingRegressor(n_estimators=25, base_estimator=Ridge(15)))])\n",
    "my_pipeline1.fit(X_train, y_train)\n",
    "predict1 = my_pipeline1.predict(X_valid)\n",
    "\n",
    "print_or_MAE(predict1, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82c5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16857.09432523546\n"
     ]
    }
   ],
   "source": [
    "my_pipeline2 = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', XGBRegressor(n_estimators=400, learning_rate = 0.05, n_jobs=4, random_state = 0))])\n",
    "my_pipeline2.fit(X_train, y_train)\n",
    "predict2 = my_pipeline2.predict(X_valid)\n",
    "print_or_MAE(predict2, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d963bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16775.110576072184\n"
     ]
    }
   ],
   "source": [
    "my_pipeline3 = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', GradientBoostingRegressor(n_estimators=200, random_state=0))])\n",
    "my_pipeline3.fit(X_train, y_train)\n",
    "predict3 = my_pipeline3.predict(X_valid)\n",
    "print_or_MAE(predict3, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6294d59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 15753.761407504324\n"
     ]
    }
   ],
   "source": [
    "predict_val = (predict1+predict2+predict3)/3\n",
    "print_or_MAE(predict_val, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f7156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0433a789",
   "metadata": {},
   "source": [
    "## apply on all data and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b2a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline1 = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', BaggingRegressor(n_estimators=25, base_estimator=Ridge(15)))])\n",
    "my_pipeline1.fit(X_full[my_cols], y)\n",
    "predict1 = my_pipeline1.predict(X_test)\n",
    "\n",
    "my_pipeline2 = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', XGBRegressor(n_estimators=400, learning_rate = 0.05, n_jobs=4))])\n",
    "my_pipeline2.fit(X_full[my_cols], y)\n",
    "predict2 = my_pipeline2.predict(X_test)\n",
    "\n",
    "my_pipeline3 = Pipeline(steps=[('precrocessor', preprocessor),\n",
    "                                 ('model', GradientBoostingRegressor(n_estimators=200))])\n",
    "my_pipeline3.fit(X_full[my_cols], y)\n",
    "predict3 = my_pipeline3.predict(X_test)\n",
    "\n",
    "predict_out = np.expm1((predict1+predict2+predict3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecdd3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': predict_out})\n",
    "output.to_csv('submission_ad.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ee44737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/chuwen/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 33.6k/33.6k [00:00<00:00, 72.6kB/s]\n",
      "Successfully submitted to Housing Prices Competition for Kaggle Learn Users"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c home-data-for-ml-course -f submission_ad.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009508e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kaggle]",
   "language": "python",
   "name": "conda-env-kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
